{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad800ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f401893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['my data',\n",
    "        'my name is ihtisham',\n",
    "        'my father name is RahmanAli', \n",
    "        'my brother name is imad',\n",
    "        'my age is 24'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b438d8e",
   "metadata": {},
   "source": [
    "# Step-1 Generate Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00841fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b4365ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5406812",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d527c6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 1,\n",
       " 'my': 2,\n",
       " 'is': 3,\n",
       " 'name': 4,\n",
       " 'data': 5,\n",
       " 'ihtisham': 6,\n",
       " 'father': 7,\n",
       " 'rahmanali': 8,\n",
       " 'brother': 9,\n",
       " 'imad': 10,\n",
       " 'age': 11,\n",
       " '24': 12}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b336c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('my', 5),\n",
       "             ('data', 1),\n",
       "             ('name', 3),\n",
       "             ('is', 4),\n",
       "             ('ihtisham', 1),\n",
       "             ('father', 1),\n",
       "             ('rahmanali', 1),\n",
       "             ('brother', 1),\n",
       "             ('imad', 1),\n",
       "             ('age', 1),\n",
       "             ('24', 1)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5381a1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d81c1e",
   "metadata": {},
   "source": [
    "# Step-2 Make Sequences of words in Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed68499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cce9f34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 5], [2, 4, 3, 6], [2, 7, 4, 3, 8], [2, 9, 4, 3, 10], [2, 11, 3, 12]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9623d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '',\n",
       " 2: 'my',\n",
       " 3: 'is',\n",
       " 4: 'name',\n",
       " 5: 'data',\n",
       " 6: 'ihtisham',\n",
       " 7: 'father',\n",
       " 8: 'rahmanali',\n",
       " 9: 'brother',\n",
       " 10: 'imad',\n",
       " 11: 'age',\n",
       " 12: '24'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceaa1f3",
   "metadata": {},
   "source": [
    "# Step-3 Apply Padding To make the Sequences of Same Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "586a2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72c9282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pad_sequences(sequences=sequences, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f1805fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  5,  0,  0,  0],\n",
       "       [ 2,  4,  3,  6,  0],\n",
       "       [ 2,  7,  4,  3,  8],\n",
       "       [ 2,  9,  4,  3, 10],\n",
       "       [ 2, 11,  3, 12,  0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7267fece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it added 0's at the end to make the squences of same sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be010894",
   "metadata": {},
   "source": [
    " ____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c5f145",
   "metadata": {},
   "source": [
    " ____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f546cf",
   "metadata": {},
   "source": [
    "# Project on IMDB Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4470412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Embedding, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "560b582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train),(x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "703872b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "imdb = np.load('C:/Users/92314/Desktop/Ehunar/Neural Network/RNN/imdb.npz', allow_pickle=True)\n",
    "lst = imdb.files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58dc28f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_test', 'x_train', 'y_train', 'y_test']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec23bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = imdb['x_train']\n",
    "y_train = imdb['y_train']\n",
    "x_test = imdb['x_test']\n",
    "y_test = imdb['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61abdbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([23022, 309, 6, 3, 1069, 209, 9, 2175, 30, 1, 169, 55, 14, 46, 82, 5869, 41, 393, 110, 138, 14, 5359, 58, 4477, 150, 8, 1, 5032, 5948, 482, 69, 5, 261, 12, 23022, 73935, 2003, 6, 73, 2436, 5, 632, 71, 6, 5359, 1, 25279, 5, 2004, 10471, 1, 5941, 1534, 34, 67, 64, 205, 140, 65, 1232, 63526, 21145, 1, 49265, 4, 1, 223, 901, 29, 3024, 69, 4, 1, 5863, 10, 694, 2, 65, 1534, 51, 10, 216, 1, 387, 8, 60, 3, 1472, 3724, 802, 5, 3521, 177, 1, 393, 10, 1238, 14030, 30, 309, 3, 353, 344, 2989, 143, 130, 5, 7804, 28, 4, 126, 5359, 1472, 2375, 5, 23022, 309, 10, 532, 12, 108, 1470, 4, 58, 556, 101, 12, 23022, 309, 6, 227, 4187, 48, 3, 2237, 12, 9, 215]),\n",
       "       list([23777, 39, 81226, 14, 739, 20387, 3428, 44, 74, 32, 1831, 15, 150, 18, 112, 3, 1344, 5, 336, 145, 20, 1, 887, 12, 68, 277, 1189, 403, 34, 119, 282, 36, 167, 5, 393, 154, 39, 2299, 15, 1, 548, 88, 81, 101, 4, 1, 3273, 14, 40, 3, 413, 1200, 134, 8208, 41, 180, 138, 14, 3086, 1, 322, 20, 4930, 28948, 359, 5, 3112, 2128, 1, 20045, 19339, 39, 8208, 45, 3661, 27, 372, 5, 127, 53, 20, 1, 1983, 7, 7, 18, 48, 45, 22, 68, 345, 3, 2131, 5, 409, 20, 1, 1983, 15, 3, 3238, 206, 1, 31645, 22, 277, 66, 36, 3, 341, 1, 719, 729, 3, 3865, 1265, 20, 1, 1510, 3, 1219, 2, 282, 22, 277, 2525, 5, 64, 48, 42, 37, 5, 27, 3273, 12, 6, 23030, 75120, 2034, 7, 7, 3771, 3225, 34, 4186, 34, 378, 14, 12583, 296, 3, 1023, 129, 34, 44, 282, 8, 1, 179, 363, 7067, 5, 94, 3, 2131, 16, 3, 5211, 3005, 15913, 21720, 5, 64, 45, 26, 67, 409, 8, 1, 1983, 15, 3261, 501, 206, 1, 31645, 45, 12583, 2877, 26, 67, 78, 48, 26, 491, 16, 3, 702, 1184, 4, 228, 50, 4505, 1, 43259, 20, 118, 12583, 6, 1373, 20, 1, 887, 16, 3, 20447, 20, 24, 3964, 5, 10455, 24, 172, 844, 118, 26, 188, 1488, 122, 1, 6616, 237, 345, 1, 13891, 32804, 31, 3, 39870, 100, 42, 395, 20, 24, 12130, 118, 12583, 889, 82, 102, 584, 3, 252, 31, 1, 400, 4, 4787, 16974, 1962, 3861, 32, 1230, 3186, 34, 185, 4310, 156, 2325, 38, 341, 2, 38, 9048, 7355, 2231, 4846, 2, 32880, 8938, 2610, 34, 23, 457, 340, 5, 1, 1983, 504, 4355, 12583, 215, 237, 21, 340, 5, 4468, 5996, 34689, 37, 26, 277, 119, 51, 109, 1023, 118, 42, 545, 39, 2814, 513, 39, 27, 553, 7, 7, 134, 1, 116, 2022, 197, 4787, 2, 12583, 283, 1667, 5, 111, 10, 255, 110, 4382, 5, 27, 28, 4, 3771, 12267, 16617, 105, 118, 2597, 5, 109, 3, 209, 9, 284, 3, 4325, 496, 1076, 5, 24, 2761, 154, 138, 14, 7673, 11900, 182, 5276, 39, 20422, 15, 1, 548, 5, 120, 48, 42, 37, 257, 139, 4530, 156, 2325, 9, 1, 372, 248, 39, 20, 1, 82, 505, 228, 3, 376, 2131, 37, 29, 1023, 81, 78, 51, 33, 89, 121, 48, 5, 78, 16, 65, 275, 276, 33, 141, 199, 9, 5, 1, 3273, 302, 4, 769, 9, 37, 17648, 275, 7, 7, 39, 276, 11, 19, 77, 6018, 22, 5, 336, 406]),\n",
       "       list([527, 117, 113, 31, 16974, 1962, 3861, 115, 902, 22590, 758, 10, 25, 123, 107, 2, 116, 136, 8, 1646, 7972, 23, 330, 5, 597, 1, 6244, 20, 390, 6, 3, 353, 14, 49, 14, 230, 8, 7673, 11900, 1, 190, 20, 9567, 6, 79, 894, 100, 109, 3609, 4, 109, 3, 36605, 3485, 43, 24, 1407, 2, 109, 12646, 1, 2405, 4, 32804, 12583, 26018, 39247, 143, 3, 2405, 26, 557, 286, 160, 712, 4122, 21720, 3, 511, 36, 1, 300, 2793, 7068, 120, 6, 774, 130, 96, 14, 3, 1165, 5285, 34, 491, 5, 4263, 1, 6788, 24, 106, 6, 50, 10557, 71, 641, 1, 1547, 133, 2, 1, 133, 118, 1, 3273, 18223, 3, 14364, 2135, 23, 29, 55, 2236, 165, 15, 1, 2974, 133, 2, 1, 104, 191, 16616, 994, 28, 26998, 11, 17, 211, 125, 254, 55, 10, 64, 9, 60, 6, 176, 397]),\n",
       "       ...,\n",
       "       list([10, 216, 77424, 233, 311, 30, 1, 21144, 19, 1410, 2, 9, 13, 28, 663, 1384, 1384, 85, 1, 766, 13, 4613, 973, 1, 10825, 4, 316, 7284, 3994, 8, 3, 4136, 4688, 17, 13, 1124, 2, 109, 3, 334, 931, 30037, 143, 21, 4, 45035, 49280, 1551, 4, 1, 1697, 10, 13, 2961, 5, 132, 52, 1994, 5, 805, 11, 17, 43, 58, 1171, 900, 1228, 5, 1, 2236, 419, 1, 766, 44, 983, 18, 1, 3230, 23, 1032, 1, 153, 2628, 57, 3994, 6, 1893, 46, 59, 132, 12, 42, 3, 205, 2820, 4, 1, 1167, 179, 8, 1, 175, 12, 1, 10732, 4, 1, 102, 2892, 3, 1285, 2, 29, 12, 3979, 18, 9, 40, 163, 1, 223, 17, 41077, 40, 37, 1, 133, 118, 3994, 211, 3537, 9, 612, 1500, 3030, 10, 283, 1014, 230, 63005, 402, 18, 128, 710, 72, 1405, 5, 232, 5051, 15, 38, 10, 158, 21, 15, 3, 783, 56, 13, 35, 832, 29, 1, 93, 2, 10, 329, 12, 1, 1378, 13, 1156, 70, 9, 6, 49, 846, 18, 161, 1562, 2241, 342, 10, 212, 971, 12, 1, 2821, 30, 1, 1410, 283, 35, 49, 35, 276, 10, 1046, 43, 139, 130, 18, 30, 1, 127, 4, 1, 17, 10, 423, 336, 533, 7159, 232, 37, 146, 16173, 69516, 171, 3999, 50, 612, 1, 83, 133, 8, 1, 1330, 6, 1290, 321, 2, 29, 18, 10, 66, 1, 2916, 8773, 4, 146, 3, 1204, 2, 50, 354, 307, 4, 1, 133, 8, 1, 6407, 1446, 748, 1, 295, 2277, 3620, 8, 7642, 42456, 8445, 965, 1132, 16, 15523, 1, 2622, 764, 2, 1333, 1521, 1, 1182, 9467, 225, 1, 828, 16846, 12600, 838, 54, 10, 40, 423, 76, 80, 11, 17, 96, 75]),\n",
       "       list([46, 105, 12, 22, 1258, 53, 15, 3, 6564, 468, 43, 5, 27, 244, 49, 31940, 1114, 105, 623, 4190, 4, 3717, 1119, 2, 295, 17, 12, 68, 84, 18, 258, 35131, 623, 46, 4956, 105, 2920, 406, 1, 6134, 4, 65, 10561, 6, 592, 37, 1, 862, 6242, 7, 7, 1, 61, 1120, 152, 10, 67, 132, 41, 11, 19, 6, 12, 42, 1279, 748, 14, 613, 14, 1, 7222, 4, 2117, 82, 71, 12, 91, 3, 52, 4113, 6825, 19, 16, 1, 1756, 18424, 4, 3, 27058, 310, 2168, 31, 3, 60431, 7, 7, 42, 74, 3209, 3297, 18, 22, 63, 78, 25, 5, 3247, 41, 3, 19, 12, 17580, 5593, 4, 1, 203, 80, 91, 1106, 717, 35, 31, 1, 55, 9, 211, 5, 1, 862, 3031, 871, 107, 9, 29, 457, 7, 7, 75, 17, 448, 77, 25, 3, 1868, 146, 1, 3067, 1779, 2383, 2494, 2, 1, 9586, 113, 4, 1, 174, 259, 1, 11200, 34, 13, 35, 75, 26, 119, 94, 69, 459, 3, 224, 2, 3597, 5, 35131, 15, 394, 8, 5, 1, 1100, 4, 180, 31, 7015, 3, 2489, 35, 75, 9, 418, 37, 10, 13, 146, 46, 1556, 53, 341, 371, 4, 3, 7790, 1186, 7, 7, 370, 370, 535, 1999, 29, 90, 535, 37, 11, 51, 1999, 1837, 3, 1067, 4, 3, 367, 18, 1138, 278, 14824, 2, 131, 105, 38137, 8, 260, 51902, 1195, 795]),\n",
       "       list([11, 6, 28, 4, 1, 7051, 105, 204, 123, 107, 9, 7244, 122, 751, 123, 549, 4, 705, 2, 1027, 5, 94, 3, 944, 4, 95, 29, 7, 7, 222, 21, 3, 683, 49, 344, 39, 106, 8, 1, 223, 944, 45, 47, 13, 3, 111, 9, 13, 32, 11620, 2, 14, 227, 14, 113, 268, 222, 161, 49, 5, 132, 35, 1812, 132, 161, 10, 1249, 2485, 388, 86, 11, 549, 4, 1832, 211, 1052, 2, 162, 623, 124, 1840, 1195, 21, 30, 46, 865, 101, 12919, 58, 555, 11, 63, 6, 3, 3814, 4, 62964, 2, 680, 9, 3, 248, 91, 592, 37, 11, 12, 44, 81, 17238, 20043, 1, 1469, 269, 37, 3, 337, 272, 19, 30, 219, 45, 22, 25, 10131, 9, 22, 771, 1050, 126, 55, 39, 275, 89, 434, 126, 55, 11, 6, 1347])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "812c2479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4ed191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e71b6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8970ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23022,\n",
       " 309,\n",
       " 6,\n",
       " 3,\n",
       " 1069,\n",
       " 209,\n",
       " 9,\n",
       " 2175,\n",
       " 30,\n",
       " 1,\n",
       " 169,\n",
       " 55,\n",
       " 14,\n",
       " 46,\n",
       " 82,\n",
       " 5869,\n",
       " 41,\n",
       " 393,\n",
       " 110,\n",
       " 138,\n",
       " 14,\n",
       " 5359,\n",
       " 58,\n",
       " 4477,\n",
       " 150,\n",
       " 8,\n",
       " 1,\n",
       " 5032,\n",
       " 5948,\n",
       " 482,\n",
       " 69,\n",
       " 5,\n",
       " 261,\n",
       " 12,\n",
       " 23022,\n",
       " 73935,\n",
       " 2003,\n",
       " 6,\n",
       " 73,\n",
       " 2436,\n",
       " 5,\n",
       " 632,\n",
       " 71,\n",
       " 6,\n",
       " 5359,\n",
       " 1,\n",
       " 25279,\n",
       " 5,\n",
       " 2004,\n",
       " 10471,\n",
       " 1,\n",
       " 5941,\n",
       " 1534,\n",
       " 34,\n",
       " 67,\n",
       " 64,\n",
       " 205,\n",
       " 140,\n",
       " 65,\n",
       " 1232,\n",
       " 63526,\n",
       " 21145,\n",
       " 1,\n",
       " 49265,\n",
       " 4,\n",
       " 1,\n",
       " 223,\n",
       " 901,\n",
       " 29,\n",
       " 3024,\n",
       " 69,\n",
       " 4,\n",
       " 1,\n",
       " 5863,\n",
       " 10,\n",
       " 694,\n",
       " 2,\n",
       " 65,\n",
       " 1534,\n",
       " 51,\n",
       " 10,\n",
       " 216,\n",
       " 1,\n",
       " 387,\n",
       " 8,\n",
       " 60,\n",
       " 3,\n",
       " 1472,\n",
       " 3724,\n",
       " 802,\n",
       " 5,\n",
       " 3521,\n",
       " 177,\n",
       " 1,\n",
       " 393,\n",
       " 10,\n",
       " 1238,\n",
       " 14030,\n",
       " 30,\n",
       " 309,\n",
       " 3,\n",
       " 353,\n",
       " 344,\n",
       " 2989,\n",
       " 143,\n",
       " 130,\n",
       " 5,\n",
       " 7804,\n",
       " 28,\n",
       " 4,\n",
       " 126,\n",
       " 5359,\n",
       " 1472,\n",
       " 2375,\n",
       " 5,\n",
       " 23022,\n",
       " 309,\n",
       " 10,\n",
       " 532,\n",
       " 12,\n",
       " 108,\n",
       " 1470,\n",
       " 4,\n",
       " 58,\n",
       " 556,\n",
       " 101,\n",
       " 12,\n",
       " 23022,\n",
       " 309,\n",
       " 6,\n",
       " 227,\n",
       " 4187,\n",
       " 48,\n",
       " 3,\n",
       " 2237,\n",
       " 12,\n",
       " 9,\n",
       " 215]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93486748",
   "metadata": {},
   "source": [
    "# Apply Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea24b0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8ae83c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a555c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the number of words in reviews are not same, so we need to apply padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14e3ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, padding='post', maxlen=50) #only pick first 50 words of the reviews\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=50) #only pick first 50 words of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d24ef78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac54f83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3724,   802,     5,  3521,   177,     1,   393,    10,  1238,\n",
       "       14030,    30,   309,     3,   353,   344,  2989,   143,   130,\n",
       "           5,  7804,    28,     4,   126,  5359,  1472,  2375,     5,\n",
       "       23022,   309,    10,   532,    12,   108,  1470,     4,    58,\n",
       "         556,   101,    12, 23022,   309,     6,   227,  4187,    48,\n",
       "           3,  2237,    12,     9,   215])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28dae90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05eafd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d752c7e7",
   "metadata": {},
   "source": [
    "# Create RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11fbd2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as there are 50 words in each review to we will take timesteps=50 so that in every timestep only a single word is passed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5d363",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"RNN timesteps.png\" width=\"500\" height=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79ee4c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 32)                1088      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(SimpleRNN(32, input_shape=(50,1), return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06a30072",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5daf3eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 13s - loss: 0.6941 - accuracy: 0.5023 - val_loss: 0.6940 - val_accuracy: 0.5018 - 13s/epoch - 17ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 10s - loss: 0.6931 - accuracy: 0.5073 - val_loss: 0.6950 - val_accuracy: 0.5080 - 10s/epoch - 13ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 8s - loss: 0.6929 - accuracy: 0.5090 - val_loss: 0.6939 - val_accuracy: 0.5080 - 8s/epoch - 11ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 8s - loss: 0.6929 - accuracy: 0.5053 - val_loss: 0.6941 - val_accuracy: 0.5001 - 8s/epoch - 11ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 9s - loss: 0.6929 - accuracy: 0.5049 - val_loss: 0.6937 - val_accuracy: 0.5027 - 9s/epoch - 11ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 8s - loss: 0.6926 - accuracy: 0.5038 - val_loss: 0.6933 - val_accuracy: 0.5070 - 8s/epoch - 11ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 9s - loss: 0.6925 - accuracy: 0.5100 - val_loss: 0.6941 - val_accuracy: 0.5089 - 9s/epoch - 11ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 8s - loss: 0.6923 - accuracy: 0.5127 - val_loss: 0.6940 - val_accuracy: 0.5048 - 8s/epoch - 11ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 9s - loss: 0.6922 - accuracy: 0.5132 - val_loss: 0.6945 - val_accuracy: 0.5024 - 9s/epoch - 12ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 8s - loss: 0.6925 - accuracy: 0.5067 - val_loss: 0.6939 - val_accuracy: 0.5055 - 8s/epoch - 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x280c2aeaca0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs=10, validation_data=(x_test,y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df85cc82",
   "metadata": {},
   "source": [
    "# What is Embedding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22accab",
   "metadata": {},
   "source": [
    "` Turns positive integers (indexes) into dense vectors of fixed size`\n",
    "\n",
    "` Dense Vector: most of the values in the vector are non-zero `\n",
    "\n",
    "` the opposite of Dense-Vector is Sparse-Vector where most of the values in the vector are zero `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b7282",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"embedding.jpg\" width=\"500\" height=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d964a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to find relation between two similar words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88f1f61",
   "metadata": {},
   "source": [
    "      1) Maps each value in the input array to a vector of defined size\n",
    "      2) the weights in the layer are learnt during the training process\n",
    "      3) initialization is perfomed just like other keras layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f44a5da",
   "metadata": {},
   "source": [
    "## Why use Embedding when we can use OneHotEncoding/ int encoding or Tokenizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d2326",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"embedding2.png\" width=\"500\" height=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c86b13",
   "metadata": {},
   "source": [
    "> `OneHotEncoding is inefficient as most indeces are zero.`\n",
    "          e.g (Text with 1000 words means most of the elements are 0)\n",
    "          \n",
    "> `Integer Encoding does not reflect the relationship between words`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6768e88e",
   "metadata": {},
   "source": [
    "## Where are Embedding Layers Used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9d270",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"embedding3.png\" width=\"600\" height=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61743eae",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"embedding4.png\" width=\"600\" height=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23036bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44a11131",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "540a633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(10, 50, embeddings_initializer='ones'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f710ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    }
   ],
   "source": [
    "input_array = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "output_array = model.predict(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1b5d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'output_array' will contain the embedded representations for each input index\n",
    "# It will have the shape (batch_size, sequence_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4e4643d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 50)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array.shape #(10,1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39f92f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaee2a29",
   "metadata": {},
   "source": [
    "`Here's an example of what each row represents:`\n",
    "\n",
    "    The first row [1., 1., 1., ...] represents the embedding vector for the input index 0.\n",
    "\n",
    "    The second row [1., 1., 1., ...] represents the embedding vector for the input index 1.\n",
    "\n",
    "    This pattern continues for the remaining rows, up to input index 9.\n",
    "\n",
    "In this specific case, all the embedding vectors are initialized to ones \n",
    "because of the 'ones' initializer i used. In practice, the embedding vectors are learned during training \n",
    "and are not typically initialized to ones, but this initialization is used here for demonstration purposes. \n",
    "During training, the model will adjust these vectors to better represent the relationships between the \n",
    "input indices based on the task it's being trained for.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55899a55",
   "metadata": {},
   "source": [
    "## Text  Preprocessing (word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f5957",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"embedding5.png\" width=\"600\" height=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b00e0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['hello how are you feeling',\n",
    "        'hello how are you doing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "514261b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e97ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ada0ec7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 1, 'how': 2, 'are': 3, 'you': 4, 'feeling': 5, 'doing': 6}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "329f58e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01fc9172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9dd548d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5], [1, 2, 3, 4, 6]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f9438d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a04f71f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 6]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27abb1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 6]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array = np.expand_dims(sequences[1], axis=0)\n",
    "input_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4b35763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding( 7, output_dim=2, embeddings_initializer='uniform',input_length=5))\n",
    "\n",
    "output_array = model.predict(input_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9cf577",
   "metadata": {},
   "source": [
    "The integers in this array range from 1 to 6. In the context of the Embedding layer, the input_dim parameter specifies the vocabulary size, which should be set to the maximum integer index that appears in your input data.\n",
    "\n",
    "In the input array [1, 2, 3, 4, 6], the maximum index is 6. \n",
    "Therefore, when defining the Embedding layer, you should set input_dim to 7 to account for all possible indices from 0 to 6, inclusive. \n",
    "This ensures that the Embedding layer can correctly map all indices to embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b975f214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.04415628,  0.00642262],\n",
       "        [ 0.0264549 , -0.00371405],\n",
       "        [ 0.04654639, -0.01473019],\n",
       "        [ 0.01705397,  0.00032941],\n",
       "        [ 0.00403158,  0.00664105]]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3934f432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bc74b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04415628,  0.00642262], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array[0][0] # 1 -> hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7ebe4da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0264549 , -0.00371405], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array[0][1] # 2 -> how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1754cdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04654639, -0.01473019], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array[0][2] # 3 -> are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2830812d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01705397, 0.00032941], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array[0][3] # 4 -> you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a993aff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00403158, 0.00664105], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_array[0][4] #6 => doing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df93600",
   "metadata": {},
   "source": [
    "#  IMDB RNN with Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9f25e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.layers import Dense, SimpleRNN, Embedding, Flatten\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f0c4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, padding='post', maxlen=50)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "299eccac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3724,   802,     5,  3521,   177,     1,   393,    10,  1238,\n",
       "       14030,    30,   309,     3,   353,   344,  2989,   143,   130,\n",
       "           5,  7804,    28,     4,   126,  5359,  1472,  2375,     5,\n",
       "       23022,   309,    10,   532,    12,   108,  1470,     4,    58,\n",
       "         556,   101,    12, 23022,   309,     6,   227,  4187,    48,\n",
       "           3,  2237,    12,     9,   215])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f068620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3724,   802,     5, ...,    12,     9,   215],\n",
       "       [   20,     1,    82, ...,     5,   336,   406],\n",
       "       [   24,   106,     6, ...,     6,   176,   397],\n",
       "       ...,\n",
       "       [ 1204,     2,    50, ...,    17,    96,    75],\n",
       "       [ 2489,    35,    75, ..., 51902,  1195,   795],\n",
       "       [   11,    63,     6, ...,    11,     6,  1347]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0af75275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88582"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3252c8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88583"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a variable to keep track of the maximum index\n",
    "max_index = 0\n",
    "\n",
    "# Iterate through all arrays in the training data\n",
    "for array in x_train:\n",
    "    max_in_array = np.max(array)\n",
    "    max_index = max(max_index, max_in_array)\n",
    "\n",
    "# Set input_dim to cover all possible indices\n",
    "input_dim = max_index + 1\n",
    "input_dim\n",
    "# Now, you can use input_dim when defining the Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6921a378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 50, 2)             177166    \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 50, 32)            1120      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50, 1)             33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 178,319\n",
      "Trainable params: 178,319\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#            vocablary_size = max + 1\n",
    "model.add(Embedding( 88583, output_dim=2, embeddings_initializer='uniform',input_length=50))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42383aa3",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"embeddin6.png\" width=\"600\" height=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0aa65dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding layer\n",
    "1000*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "343b9510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN layer\n",
    "(2*32) + (32*32) + 32 # -> last 32 is bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4cffd035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dense layer\n",
    "32 + 1  # -> 1 is bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "94dbddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our vectorized labels\n",
    "y_tr = np.asarray(y_train).astype('int32').reshape((-1,1))\n",
    "y_te = np.asarray(y_test).astype('int32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "883c843d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f2a571d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 14s - loss: 0.6012 - accuracy: 0.6585 - val_loss: 0.5570 - val_accuracy: 0.7093 - 14s/epoch - 18ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 13s - loss: 0.4692 - accuracy: 0.7729 - val_loss: 0.5720 - val_accuracy: 0.7054 - 13s/epoch - 17ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 13s - loss: 0.3918 - accuracy: 0.8198 - val_loss: 0.5852 - val_accuracy: 0.6854 - 13s/epoch - 16ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 12s - loss: 0.3394 - accuracy: 0.8481 - val_loss: 0.6610 - val_accuracy: 0.6877 - 12s/epoch - 16ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 12s - loss: 0.3021 - accuracy: 0.8655 - val_loss: 0.7265 - val_accuracy: 0.6774 - 12s/epoch - 15ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 12s - loss: 0.2783 - accuracy: 0.8760 - val_loss: 0.8192 - val_accuracy: 0.6736 - 12s/epoch - 16ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 12s - loss: 0.2574 - accuracy: 0.8851 - val_loss: 0.8181 - val_accuracy: 0.6678 - 12s/epoch - 15ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 12s - loss: 0.2443 - accuracy: 0.8903 - val_loss: 0.9277 - val_accuracy: 0.6607 - 12s/epoch - 15ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 11s - loss: 0.2319 - accuracy: 0.8949 - val_loss: 0.8184 - val_accuracy: 0.6623 - 11s/epoch - 14ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 11s - loss: 0.2242 - accuracy: 0.8980 - val_loss: 1.0545 - val_accuracy: 0.6542 - 11s/epoch - 14ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train,y_tr, validation_data=(x_test,y_te), epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "60d17566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d0e0d3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5ca6ac8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad9b1304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a4b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add an Embedding layer\n",
    "model.add(Embedding(input_dim=88583, output_dim=2, input_length=50))\n",
    "\n",
    "# Add a SimpleRNN layer\n",
    "model.add(SimpleRNN(64))\n",
    "\n",
    "# Add a Dense layer for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model5\n",
    "history = model.fit(x_train, y_tr, validation_data=(x_test, y_te), batch_size=24, epochs=5, verbose=2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f2d86165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 4ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79     12500\n",
      "           1       0.81      0.72      0.77     12500\n",
      "\n",
      "    accuracy                           0.78     25000\n",
      "   macro avg       0.78      0.78      0.78     25000\n",
      "weighted avg       0.78      0.78      0.78     25000\n",
      "\n",
      "Accuracy: 0.7786\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels (e.g., for binary classification)\n",
    "y_pred_class = (y_pred > 0.5).astype(np.int32)\n",
    "\n",
    "# Print classification report (includes precision, recall, F1-score, etc.)\n",
    "report = classification_report(y_test, y_pred_class)\n",
    "print('Classification Report:\\n', report)\n",
    "\n",
    "\n",
    "# Calculate and print accuracy.\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_class)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "771eb242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = [\"the movie was good\"]\n",
    "\n",
    "# Load the tokenizer used during training\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text) \n",
    "\n",
    "# Tokenize the input text and convert it to an integer sequence\n",
    "input_sequence = tokenizer.texts_to_sequences([text])\n",
    "\n",
    "# Pad the sequence to match the input shape expected by the model\n",
    "max_sequence_length = 50\n",
    "input_sequence = pad_sequences(input_sequence, maxlen=max_sequence_length)\n",
    "\n",
    "# Make the prediction\n",
    "prediction = model.predict(input_sequence)\n",
    "\n",
    "# Interpret the prediction (e.g., determine if it's positive or negative sentiment)\n",
    "# In binary classification, we use a threshold to interpret the prediction\n",
    "threshold = 0.5\n",
    "sentiment_label = \"positive\" if prediction[0][0] > threshold else \"negative\"\n",
    "\n",
    "print(f\"Predicted sentiment: {sentiment_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97cb71",
   "metadata": {},
   "source": [
    "Fine-Tuning the Model:\n",
    "\n",
    "Experiment with different model architectures and hyperparameters to find the best configuration for your task.\n",
    "Adjust the number of layers and units in your neural network.\n",
    "Explore more advanced techniques like bidirectional RNNs, LSTM, GRU, or pre-trained embeddings like Word2Vec or GloVe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82009222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
